{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Analyze-Daily-and-Minute-Bar.ipynb","provenance":[],"authorship_tag":"ABX9TyOpP0Iq0TfHO61J1MqciPcU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pHxcj1GHRqd4"},"source":["\n","# テーマ：日足とその日の初めの分足の足型が一致するかを分析する\n","\n","# 仕様\n","* 東証上場銘柄（4,000社以上）を対象とする\n","  * https://www.jpx.co.jp/markets/statistics-equities/misc/01.html より銘柄一覧をダウンロードし、tickers.csvとして保管しておく。この際、銘柄コードの列名はtickerとする\n","* 指定した日数の日足と分足（デフォルトでは5分足）の株価をYahooから取得し、日足とその日の初めの分足の足型が一致するかを分析する。結果はresult.csvに出力する。result.csvの各列は以下の通り\n","  * match_rate：方向性が一致した割合\n","  * match_count：方向性が一致した数\n","  * whole_count：日足の数\n","  * average_volume：出来高の平均値（日足ベース）\n","  * average_price：株価の平均値（日足の終値ベース）\n","* Yahooから株価を取得する際、サーバー負荷をかけすぎないようにするため、一定秒数（デフォルトでは5秒）待ってから次の銘柄のデータをダウンロードする。そのため全銘柄ダウンロードするには6時間以上かかる\n","* 再ダウンロードの機会を減らすため、取得したJSONをファイルに出力（json_dataディレクトリ以下）\n","\n","# 出来ていないこと\n","* ローカルファイル（保管したCSVファイル）を利用した分析\n","\n","# 今回参考にしたもの\n","* https://note.com/aiduudia/n/na9ea4f90e255\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nDYf1SzBVA2I"},"source":["# 1. Preparation"]},{"cell_type":"code","metadata":{"id":"_YHiPkT4j4TT"},"source":["# Google Driveのマウント\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/'My Drive'/'プログラム（株）'/日足と分足の関連分析"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9aCDc7S9mRq"},"source":["# Hyper Dashのインストールとサインアップ\n","!pip install hyperdash\n","from hyperdash import monitor_cell\n","!hyperdash signup --github"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eFnZkw8iVKS2"},"source":["# 2. Main"]},{"cell_type":"code","metadata":{"id":"k44nOfnbkF6n","executionInfo":{"status":"ok","timestamp":1619863589469,"user_tz":-540,"elapsed":721,"user":{"displayName":"Keisuke Shoji","photoUrl":"","userId":"10321049352155053308"}}},"source":["import requests\n","import json\n","import pandas as pd\n","from datetime import datetime, timedelta, timezone\n","from statistics import mean\n","\n","# 定数、グローバル変数\n","RANGE = '60d' # 何日間のデータを取得するか\n","DAY_INTERVAL = '1d'\n","MINUTE_INTERVAL = '5d' # 分足は5分足をデフォルトとする\n","VOLUME_CRITERIA = 200000 # 出来高がこれより少ないものは無視する\n","INTERVAL_SECOND = 5 # この秒数待ってから次の銘柄のデータをダウンロードする\n","\n","JST = timezone(timedelta(hours=+9), 'JST')\n","\n","# Yahooから株価データを取得\n","def get_price_data_from_yahoo(ticker):\n","  json_day, json_minute = None, None\n","\n","  # 日足取得\n","  response_day = requests.get('https://query1.finance.yahoo.com/v7/finance/chart/' \\\n","                              + ticker + '?range=' + RANGE + '&interval=' + DAY_INTERVAL + '&indicators=quote&includeTimestamps=true')\n","  \n","  if 200 <= response_day.status_code < 300:\n","    json_day = response_day.json()\n","    \n","    # 平均出来高が基準未満であれば以降の処理をスキップ\n","    volume = 0\n","    average_volume = 0\n","    if 'volume' in json_day['chart']['result'][0]['indicators']['quote'][0]:\n","      volume = json_day['chart']['result'][0]['indicators']['quote'][0]['volume']\n","      average_volume = mean(d for d in volume if d is not None)\n","    \n","    if volume is None or average_volume < VOLUME_CRITERIA:\n","      return None, None\n","    \n","    # データを再利用可能にするため、JSONファイルを保管\n","    start_date = extract_date(json_day['chart']['result'][0]['timestamp'][0])\n","    end_date = extract_date(json_day['chart']['result'][0]['timestamp'][-1])\n","    save_json(json_day, r'./json_data/' + f'{ticker}_day_{start_date}_{end_date}.json')\n","\n","  # 分足取得\n","  response_minute = requests.get('https://query1.finance.yahoo.com/v7/finance/chart/' \\\n","                              + ticker + '?range=' + RANGE + '&interval=' + MINUTE_INTERVAL + '&indicators=quote&includeTimestamps=true')\n","  \n","  if 200 <= response_minute.status_code < 300:\n","    json_minute = response_minute.json()\n","\n","    # データを再利用可能にするため、JSONファイルを保管\n","    start_date = extract_date(json_minute['chart']['result'][0]['timestamp'][0])\n","    end_date = extract_date(json_minute['chart']['result'][0]['timestamp'][-1])\n","    save_json(json_minute, r'./json_data/' + f'{ticker}_minute_{start_date}_{end_date}.json')\n","\n","  return json_day, json_minute\n","\n","# タイムスタンプから日付を取得\n","def extract_date(timestamp):\n","  date_and_time = str(datetime.fromtimestamp(timestamp))\n","  date, _ = date_and_time.split()\n","  return date\n","\n","# JSONファイル保存\n","def save_json(json_data, file_path):\n","  with open(file_path, 'w') as f:\n","    json.dump(json_data, f, indent=2)\n","\n","# 株価データ（JSON）をデータフレームに変換\n","def convert_to_dataframe(json_day, json_minute):\n","  # 日足\n","  if json_day['chart']['result'] == None or 'timestamp' not in json_day['chart']['result'][0]:\n","    return None, None\n","  df_day = pd.DataFrame()\n","  df_day['timestamp'] = list(map(datetime.fromtimestamp, json_day['chart']['result'][0]['timestamp'], [JST]*len(json_day['chart']['result'][0]['timestamp'])))\n","  df_day['open'] = json_day['chart']['result'][0]['indicators']['quote'][0]['open']\n","  df_day['low'] = json_day['chart']['result'][0]['indicators']['quote'][0]['low']\n","  df_day['high'] = json_day['chart']['result'][0]['indicators']['quote'][0]['high']\n","  df_day['close'] = json_day['chart']['result'][0]['indicators']['quote'][0]['close']\n","  df_day['volume'] = json_day['chart']['result'][0]['indicators']['quote'][0]['volume']\n","  df_day['positive'] = df_day['open'] < df_day['close']\n","  df_day['minute_positive'] = None\n","\n","  # 5分足\n","  if json_minute['chart']['result'] == None or 'timestamp' not in json_minute['chart']['result'][0]:\n","    return None, None\n","  df_minute = pd.DataFrame()\n","  df_minute['timestamp'] = list(map(datetime.fromtimestamp, json_minute['chart']['result'][0]['timestamp'], [JST]*len(json_minute['chart']['result'][0]['timestamp'])))\n","  df_minute['open'] = json_minute['chart']['result'][0]['indicators']['quote'][0]['open']\n","  df_minute['low'] = json_minute['chart']['result'][0]['indicators']['quote'][0]['low']\n","  df_minute['high'] = json_minute['chart']['result'][0]['indicators']['quote'][0]['high']\n","  df_minute['close'] = json_minute['chart']['result'][0]['indicators']['quote'][0]['close']\n","  df_minute['volume'] = json_minute['chart']['result'][0]['indicators']['quote'][0]['volume']\n","\n","  return df_day, df_minute\n","\n","# 日足の方向性（陽線/陰線）とその日の初めの5分足の方向性が一致している割合を算出\n","def analyze_direction(df_day, df_minute, index, df_result):\n","  # その日の初めの5分足が陽線かどうかをチェック\n","  for row_day in df_day.itertuples():\n","    for row_minute in df_minute.itertuples():\n","      if row_day.timestamp.date() == row_minute.timestamp.date():\n","        # 出来高0の場合は無視する\n","        if row_minute.volume <= 0:\n","          continue\n","        df_day.at[row_day[0], 'minute_positive'] = row_minute.open < row_minute.close\n","        break\n","\n","  df_day['same_direction'] = [1 if r.positive == r.minute_positive else 0 for r in df_day.itertuples()]\n","\n","  df_result.at[index, 'match_rate'] = df_day['same_direction'].sum() / df_day['same_direction'].count()\n","  df_result.at[index, 'match_count'] = df_day['same_direction'].sum()\n","  df_result.at[index, 'whole_count'] = df_day['same_direction'].count()\n","  df_result.at[index, 'average_volume'] = df_day['volume'].mean()\n","  df_result.at[index, 'average_price'] = df_day['close'].mean()\n","\n","# 一連の処理\n","def analyzer(ticker, df_result, index):\n","  json_day, json_minute = get_price_data_from_yahoo(ticker)\n","  if json_day is None or json_minute is None:\n","    return\n","\n","  df_day, df_minute = convert_to_dataframe(json_day, json_minute)\n","  if df_day is None or df_minute is None:\n","    return\n","\n","  analyze_direction(df_day, df_minute, index, df_result)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"moAHuKRonCDN"},"source":["%%monitor_cell 'Analyzer'\n","\n","import codecs\n","import time\n","from IPython.display import display\n","\n","#df_result = pd.read_csv('./tickers.csv')\n","# UTF-8のエラー対応のため上のコードの代わりに次のコードを実行し、銘柄コード一覧を取得\n","with codecs.open('./tickers.csv', 'r', 'UTF-8', 'ignore') as file:\n","  df_result = pd.read_table(file, delimiter=',')\n","\n","# 東証前提のため銘柄コードの末尾に.Tを付与\n","df_result['ticker'] = list(map(str, df_result['ticker']))\n","df_result['ticker'] = df_result['ticker'] + '.T'\n","\n","start = time.time()\n","\n","for row in df_result.itertuples():\n","  analyzer(row.ticker, df_result, row[0])\n","  time.sleep(INTERVAL_SECOND)\n","  if row[0] % 100 == 99:\n","  # if row[0] % 10 == 3: # テスト用コード\n","    process_time = time.time() - start\n","    print(f'{str(row[0]+1)}社目のデータ取得後の結果（これまで{str(round(process_time/60, 1))}分経過）')\n","    display(df_result.sort_values('match_rate', ascending=False))\n","\n","df_result = df_result.dropna(how='any')\n","if 'match_count' in df_result:\n","  df_result['match_count'] = list(map(int, df_result['match_count']))\n","if 'whole_count' in df_result:\n","  df_result['whole_count'] = list(map(int, df_result['whole_count']))\n","\n","df_result.to_csv('./result.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9EKAtaz3VhsO"},"source":["# 3. Code Snippet"]},{"cell_type":"code","metadata":{"id":"yAsc1JJU5nNC"},"source":["# デバッガー\n","%debug"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D3vnhKiAjqMv"},"source":["# デバッグするときは次のコードをブレイクポイントに設定\n","from IPython.core.debugger import Pdb; Pdb().set_trace()\n","\n","# ノートブックの稼働時間を調べたいときは次のコードを別ノートブックで実行\n","!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 / 60 / 60 \"h)\"}'"],"execution_count":null,"outputs":[]}]}